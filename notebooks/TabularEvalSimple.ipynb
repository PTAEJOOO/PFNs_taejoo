{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from train import train\n",
    "import priors\n",
    "import utils\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_openml_list, valid_dids_classification, test_dids_classification\n",
    "from tabular import evaluate, get_model, get_default_spec\n",
    "from tabular import bayes_net_metric, gp_metric, knn_metric, ridge_metric, catboost_metric, xgb_metric, logistic_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loads small list of datasets\n",
    "print('Loading test datasets...')\n",
    "test_datasets, test_datasets_df = load_openml_list(test_dids_classification[0:2], filter_for_nan=True)\n",
    "ds = test_datasets\n",
    "\n",
    "print('\\n Loading valid datasets...')\n",
    "valid_datasets, valid_datasets_df = load_openml_list(valid_dids_classification[0:2], filter_for_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loads all datasets\n",
    "print('Loading test datasets...')\n",
    "test_datasets, test_datasets_df = load_openml_list(test_dids_classification, filter_for_nan=True)\n",
    "ds = test_datasets\n",
    "\n",
    "print('\\n Loading valid datasets...')\n",
    "valid_datasets, valid_datasets_df = load_openml_list(valid_dids_classification, filter_for_nan=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After how many training samples should evaluatuion be done?\n",
    "# Trained models have not been trained to evaluate after 30 samples\n",
    "# so performance will drop\n",
    "eval_positions = [30]\n",
    "\n",
    "# What is the maximum number of features?\n",
    "# Pretrained models have to use 60\n",
    "max_features = 60\n",
    "\n",
    "# How many samples should be loaded for one dataset?\n",
    "# Samples after the training sequence are used for evaluation\n",
    "seq_len = 100\n",
    "\n",
    "# How many subsamples of datasets should be drawn for each dataset\n",
    "max_samples = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_model_checkpoint_dir = \"../results/tabular_model_gp.ckpt\"\n",
    "gp_model_config = {'batch_size': 512,\n",
    " 'bptt': 100,\n",
    " 'dropout': 0.5,\n",
    " 'emsize': 512,\n",
    " 'epochs': 100,\n",
    " 'eval_positions': [10, 20, 40, 80],\n",
    " 'lr': 6.271726842985807e-05,\n",
    " 'nhead': 4,\n",
    " 'nhid_factor': 2,\n",
    " 'nlayers': 5,\n",
    " 'num_features': 60,\n",
    " 'prior_lengthscale': 0.00014803074521613278,\n",
    " 'prior_noise': 0.001,\n",
    " 'prior_normalize_by_used_features': True,\n",
    " 'prior_num_features_used_sampler': {'uniform_int_sampler_f(1,max_features)': '<function <lambda>.<locals>.<lambda> at 0x7f21e832e550>'},\n",
    " 'prior_order_y': False,\n",
    " 'prior_outputscale': 2.3163584733185836,\n",
    " 'prior_type': 'gp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_model_checkpoint_dir = \"../results/tabular_model_bnn.ckpt\"\n",
    "bnn_model_config = {'batch_size': 512,\n",
    " 'bptt': 50,\n",
    " 'dropout': 0.5,\n",
    " 'emsize': 512,\n",
    " 'epochs': 100,\n",
    " 'eval_positions': [10, 20, 40],\n",
    " 'lr': 1.6421403128751275e-05,\n",
    " 'nhead': 4,\n",
    " 'nhid_factor': 2,\n",
    " 'nlayers': 5,\n",
    " 'num_features': 60,\n",
    " 'prior_activations': \"<class 'torch.nn.modules.activation.Tanh'>\",\n",
    " 'prior_dropout_sampler': {'lambda: 0.0': '<function <lambda> at 0x7f613c1364c0>'},\n",
    " 'prior_emsize_sampler': {'scaled_beta_sampler_f(2.0, 4.0, 150, 2)': '<function <lambda>.<locals>.<lambda> at 0x7f613c136310>'},\n",
    " 'prior_is_causal': False,\n",
    " 'prior_nlayers_sampler': {'lambda: 3': '<function <lambda> at 0x7f613c136790>'},\n",
    " 'prior_noise_std_gamma_k': 1.8663049257557085,\n",
    " 'prior_noise_std_gamma_theta': 0.05275478076173361,\n",
    " 'prior_normalize_by_used_features': False,\n",
    " 'prior_num_features_used_sampler': {'scaled_beta_sampler_f(1.0, 1.6, max_features, 2)': '<function <lambda>.<locals>.<lambda> at 0x7f613c136550>'},\n",
    " 'prior_order_y': True,\n",
    " 'prior_sigma_gamma_k': 3.6187797729244253,\n",
    " 'prior_sigma_gamma_theta': 0.06773738681062867,\n",
    " 'prior_type': 'mlp'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading PFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'bnn'\n",
    "if model_type == 'gp':\n",
    "    raise Exception(\"Not Implemented\")\n",
    "    config = gp_model_config\n",
    "    checkpoint_dir = gp_model_checkpoint_dir\n",
    "elif model_type == 'bnn':\n",
    "    config = bnn_model_config\n",
    "    checkpoint_dir = bnn_model_checkpoint_dir\n",
    "\n",
    "model = get_model(config, device, eval_positions, should_train=False)\n",
    "model_state, _ = torch.load(checkpoint_dir)\n",
    "model[2].load_state_dict(model_state)\n",
    "model = model[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of PFN and Baselines on all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "result = evaluate(ds, model.to(device), 'transformer'\n",
    "                  , max_features = max_features\n",
    "                  , bptt=seq_len\n",
    "                  , eval_position_range=eval_positions\n",
    "                  , device=device\n",
    "                  , max_samples=20\n",
    "                  , rescale_features=config[\"prior_normalize_by_used_features\"]\n",
    "                  , extend_features=True, plot=False, overwrite=True, save=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = evaluate(ds, knn_metric, 'knn'\n",
    "                  , bptt=seq_len\n",
    "                  , eval_position_range=eval_positions\n",
    "                  , device=device\n",
    "                  , max_samples=20\n",
    "                  , overwrite=True\n",
    "                  , save=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = evaluate(ds, logistic_metric, 'logistic'\n",
    "                  , bptt=seq_len\n",
    "                  , eval_position_range=eval_positions\n",
    "                  , device=device\n",
    "                  , max_samples=20\n",
    "                  , overwrite=True\n",
    "                  , save=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = evaluate(ds, gp_metric, 'gp'\n",
    "                  , bptt=seq_len\n",
    "                  , eval_position_range=eval_positions\n",
    "                  , device=device\n",
    "                  , max_samples=20\n",
    "                  , overwrite=True\n",
    "                  , save=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = evaluate(ds, xgb_metric, 'xgb'\n",
    "                  , bptt=seq_len\n",
    "                  , eval_position_range=eval_positions\n",
    "                  , device=device\n",
    "                  , max_samples=20\n",
    "                  , overwrite=True\n",
    "                  , save=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "### Bayesian NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = evaluate(ds, bayes_net_metric, 'bayes_net'\n",
    "                  , bptt=seq_len\n",
    "                  , eval_position_range=eval_positions\n",
    "                  , device=device\n",
    "                  , max_samples=20\n",
    "                  , overwrite=True\n",
    "                  , save=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = evaluate(ds, catboost_metric, 'catboost'\n",
    "                  , bptt=seq_len\n",
    "                  , eval_position_range=eval_positions\n",
    "                  , device=device\n",
    "                  , max_samples=20\n",
    "                  , overwrite=True\n",
    "                  , save=False)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
